#
# SERVER
#
server.contextPath=/progsets
server.port=8174

spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\
							 org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\
							 org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration

procsets.spark.appname=procsetspsql
#procsets.spark.master=spark://diapp-nprd1-101:7077
procsets.spark.master=local

#
# Entity Configuration Store - Mongodb
#
#mongodb
procsets.config.store.mongodb.hosts=clip-stg-01:27017
procsets.config.store.mongodb.database=dgmsprog

#logging
logging.level.org.springframework.data=debug
logging.level.=error

#
# Encryption Key - must be 8 chars/bytes
#
procsets.cryptkey=10102020


#
# Procsets procedures default settings
#
procsets.proc.ielastic.default.datasource=defaultelastic
procsets.proc.imongo.default.datasource=defaultmongo

procsets.proc.solr.default.datasource=defaultsolr
#procsets.proc.solr.default.solr.max_rows=1000
procsets.proc.solr.default.solr.rows=500
#procsets.proc.solr.default.solr.max_rows=10000

procsets.proc.cassandra.default.datasource=defaultcassandra

#
# procsets default data source configuration
#
# # Format: 
#   
# procsets.spark.<datasource name to reference in PSQL>.<connector conf name>
#
#

# Elastic - Spark Configuration
# https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html
procsets.spark.datasource.defaultelastic.spark.read.format=es
procsets.spark.datasource.defaultelastic.es.mapping.date.rich=false
procsets.spark.datasource.defaultelastic.es.nodes=clip-stg-07
procsets.spark.datasource.defaultelastic.es.port=9100
procsets.spark.datasource.defaultelastic.es.read.field.include=source,path,gl2_source_input,timestamp

# Mongo - Spark 
# https://docs.mongodb.com/spark-connector/current/configuration/
procsets.spark.datasource.defaultmongo.spark.read.format=com.mongodb.spark.sql
procsets.spark.datasource.defaultmongo.spark.mongodb.input.uri=mongodb://clip-stg-01:27017
#procsets.spark.datasource.defaultmongo.spark.mongodb.input.database=graylog_clip_on_clip
#procsets.spark.datasource.defaultmongo.spark.mongodb.input.database=graylog_clip_on_clip
procsets.spark.datasource.defaultmongo.spark.mongodb.input.partitioner=MongoShardedPartitioner

#
#Solr Spark Configuration
#https://github.com/lucidworks/spark-solr#connect-to-your-solrcloud-instance
#https://github.com/lucidworks/spark-solr#configuration-and-tuning
procsets.spark.datasource.defaultsolr.spark.read.format=solr
procsets.spark.datasource.defaultsolr.solr.zkhost=diapp-prd1-55:2181,diapp-prd1-56:2181,diapp-prd1-57:2181
procsets.spark.datasource.defaultsolr.solr.collection=ccoidcbp
procsets.spark.datasource.defaultsolr.solr.sort=UNIQUE_ID
procsets.spark.datasource.defaultsolr.solr.fields=UNIQUE_ID

#
#
#
procsets.spark.datasource.cbpheader.spark.read.format=solr
procsets.spark.datasource.cbpheader.solr.zkhost=diapp-nprd1-131:2182,diapp-nprd1-132:2182,diapp-nprd1-133:2182
procsets.spark.datasource.cbpheader.solr.collection=cbpHeader
procsets.spark.datasource.cbpheader.solr.sort=UNIQUE_ID
procsets.spark.datasource.cbpheader.solr.fields=UNIQUE_ID,XDSC_BILLTO_GU_ID,XDSC_SERVICE_LINE_ID,XDSC_COVERAGE_END_DATE,XDSC_SERVICE_LINE_NAME,XDSC_COVERAGE_TEMPLATE_DESC,XDSC_SERVICE_LINE_STS_CODE,XDSC_BILLTO_GU_NAME,XDSC_CONTRACT_START_DATE,XDSC_COVERAGE_BEGIN_DATE,DISP_LAST_UPDATED_BY,XDSC_SERVICE_LINE_STATUS,XDSC_CONTRACT_STS_CODE,XDSC_BILL_TO_SITE_USE_NAME,XDSC_BILL_TO_PARTY_ID,XDSC_CONTRACT_STATUS,XDSC_CONTRACT_ID,ENTITLED_PARTY_FLAG,XDSC_CONTRACT_END_DATE,SL_IL_ID,XDSC_CONTRACT_NUMBER,XDSC_BILL_TO_SITE_USE_ID,XDSC_BILL_TO_CUSTOMER_NAME,DISP_LAST_MODIFIED_DATE

#
#
#
procsets.spark.datasource.cbs2.spark.read.format=solr
procsets.spark.datasource.cbs2.solr.zkhost=diapp-nprd1-64:2181,diapp-nprd1-65:2181,diapp-nprd1-67:2181
procsets.spark.datasource.cbs2.solr.collection=cbs2
procsets.spark.datasource.cbs2.solr.sort=UNIQUE_ID
procsets.spark.datasource.cbs2.solr.fields=UNIQUE_ID,XDCD_COVERED_LINE_ID,XDID_PO_NUMBER,XDCD_SERVICE_LINE_ID,XDID_INSTANCE_ID,XDID_SERIAL_NUMBER,CPL_STATUS,XDID_INSTALL_LOCATION_ID,MSIB_ITEM_NAME,MSIB_INVENTORY_ITEM_ID,XDID_DUP_SERIAL_NUMBER

#
#https://github.com/datastax/spark-cassandra-connector/blob/master/doc/reference.md#cassandra-connection-parameters
#
procsets.spark.datasource.defaultcassandra.spark.read.format=org.apache.spark.sql.cassandra
procsets.spark.datasource.defaultcassandra.spark.cassandra.connection.host=104.154.245.230
#procsets.spark.datasource.defaultcassandra.spark.cassandra.connection.port=9042

#  CLIP On CLIP ES 
# https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html
#
#
procsets.spark.datasource.cliponclip.spark.read.format=es
procsets.spark.datasource.cliponclip.es.mapping.date.rich=false
procsets.spark.datasource.cliponclip.es.nodes=clip-prod-134
procsets.spark.datasource.cliponclip.es.port=9100
#procsets.spark.datasource.cliponclip.es.index=winlogbeat_*
#procsets.spark.datasource.defaultelastic.es.read.field.include=

