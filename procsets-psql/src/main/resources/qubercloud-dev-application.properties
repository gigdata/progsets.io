#
# SERVER
#
server.contextPath=/progsets
server.port=8174


procsets.spark.appname=quberprocsets
procsets.spark.master=local[4]
#procsets.spark.master=spark://35.200.249.193:7077

spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\
							 org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\
							 org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration



#
# Entity Configuration Store - Mongodb
#
#mongodb
procsets.config.store.mongodb.hosts=cloud.qubercomm.com:27017
procsets.config.store.mongodb.database=procsets

#logging
logging.level.org.springframework.data=debug
logging.level.=error

#
# Encryption Key - must be 8 chars/bytes
#
procsets.cryptkey=10102020


# Procsets procedures default settings
#
procsets.proc.ielastic.default.datasource=qubercloud-elastic
procsets.proc.ielastic.default.es.nodes.discovery=false
procsets.proc.ielastic.default.es.mapping.date.rich=false
procsets.proc.imongo.default.datasource=qubercloud-mongodb


#
# procsets default data source configuration
#
# # Format: 
#   
# procsets.spark.<datasource name to reference in PSQL>.<connector conf name>
#
#

# Elastic - Spark Configuration
# https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html
procsets.spark.datasource.qubercloud-elastic.spark.read.format=es
procsets.spark.datasource.qubercloud-elastic.es.nodes=cloud.qubercomm.com
procsets.spark.datasource.qubercloud-elastic.es.port=9200
procsets.spark.datasource.qubercloud-elastic.es.nodes.wan.only=true
procsets.spark.datasource.qubercloud-elastic.es.read.field.exclude=streams
#procsets.spark.datasource.defaultelastic.es.read.field.include=source,path,gl2_source_input,timestamp


# Mongo - Spark 
# https://docs.mongodb.com/spark-connector/current/configuration/
procsets.spark.datasource.qubercloud-mongodb.spark.read.format=com.mongodb.spark.sql
procsets.spark.datasource.qubercloud-mongodb.spark.mongodb.input.uri=mongodb://cloud.qubercomm.com:27017
procsets.spark.datasource.qubercloud-mongodb.spark.mongodb.input.database=facesix


#
#My SQL
#
procsets.spark.datasource.facesix-stock.spark.read.format=jdbc
procsets.spark.datasource.facesix-stock.url=jdbc:mysql://10.128.0.2:3306/procsets
procsets.spark.datasource.facesix-stock.driver=com.mysql.jdbc.Driver
procsets.spark.datasource.facesix-stock.user=procsets
procsets.spark.datasource.facesix-stock.password=procsetspwd