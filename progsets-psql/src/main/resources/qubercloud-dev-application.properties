#
# SERVER
#
server.contextPath=/progsets
server.port=8174


progsets.spark.appname=quberprogsets
progsets.spark.master=local[4]
#progsets.spark.master=spark://35.200.249.193:7077

spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\
							 org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\
							 org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration



#
# Entity Configuration Store - Mongodb
#
#mongodb
progsets.config.store.mongodb.hosts=cloud.qubercomm.com:27017
progsets.config.store.mongodb.database=progsets

#logging
logging.level.org.springframework.data=debug
logging.level.=error

#
# Encryption Key - must be 8 chars/bytes
#
progsets.cryptkey=10102020


# progsets procedures default settings
#
progsets.proc.ielastic.default.datasource=qubercloud-elastic
progsets.proc.ielastic.default.es.nodes.discovery=false
progsets.proc.ielastic.default.es.mapping.date.rich=false
progsets.proc.imongo.default.datasource=qubercloud-mongodb


#
# progsets default data source configuration
#
# # Format: 
#   
# progsets.spark.<datasource name to reference in PSQL>.<connector conf name>
#
#

# Elastic - Spark Configuration
# https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html
progsets.spark.datasource.qubercloud-elastic.spark.read.format=es
progsets.spark.datasource.qubercloud-elastic.es.nodes=cloud.qubercomm.com
progsets.spark.datasource.qubercloud-elastic.es.port=9200
progsets.spark.datasource.qubercloud-elastic.es.nodes.wan.only=true
progsets.spark.datasource.qubercloud-elastic.es.read.field.exclude=streams
#progsets.spark.datasource.defaultelastic.es.read.field.include=source,path,gl2_source_input,timestamp


# Mongo - Spark 
# https://docs.mongodb.com/spark-connector/current/configuration/
progsets.spark.datasource.qubercloud-mongodb.spark.read.format=com.mongodb.spark.sql
progsets.spark.datasource.qubercloud-mongodb.spark.mongodb.input.uri=mongodb://cloud.qubercomm.com:27017
progsets.spark.datasource.qubercloud-mongodb.spark.mongodb.input.database=facesix


#
#My SQL
#
progsets.spark.datasource.facesix-stock.spark.read.format=jdbc
progsets.spark.datasource.facesix-stock.url=jdbc:mysql://10.128.0.2:3306/progsets
progsets.spark.datasource.facesix-stock.driver=com.mysql.jdbc.Driver
progsets.spark.datasource.facesix-stock.user=progsets
progsets.spark.datasource.facesix-stock.password=progsetspwd