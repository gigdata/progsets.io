
#
# SERVER
#
server.contextPath=/progsets
server.port=8175

progsets.spark.appname=progsets00
progsets.spark.master=local


spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\
							 org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\
							 org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\
							 org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration

#
# Entity Configuration Store - Mongodb
#
#mongodb
progsets.config.store.mongodb.hosts=localhost:27017
progsets.config.store.mongodb.database=progsets

#logging
logging.level.org.springframework.data=debug
logging.level.=error

#
# Encryption Key - must be 8 chars/bytes
#
progsets.cryptkey=10102020

#
#Basic Auth
#
progsets.auth=admin:admin

#
# progsets procedures default settings
#
progsets.proc.ielastic.default.datasource=defaultelastic
progsets.proc.ijdbc.default.datasource=defaultrdbms
progsets.proc.imongo.default.datasource=defaultmongodb
progsets.proc.isolr.default.datasource=defaultsolr
progsets.proc.icassandra.default.datasource=defaultcassandra


#
# Elastic - Spark Configuration
#
# https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html
#
progsets.spark.datasource.defaultelastic.spark.read.format=org.elasticsearch.spark.sql
progsets.spark.datasource.defaultelastic.es.mapping.date.rich=false
progsets.spark.datasource.defaultelastic.es.nodes=localhost
progsets.spark.datasource.defaultelastic.es.port=9200
progsets.spark.datasource.defaultelastic.es.net.http.auth.user=elastic
progsets.spark.datasource.defaultelastic.es.net.http.auth.pass=changeme
progsets.spark.datasource.defaultelastic.es.nodes.discovery=false

#
#My SQL
#
#https://spark.apache.org/docs/latest/sql-programming-guide.html#jdbc-to-other-databases
#
progsets.spark.datasource.defaultrdbms.spark.read.format=jdbc
progsets.spark.datasource.defaultrdbms.url=jdbc:mysql://localhost:3306/progsets
progsets.spark.datasource.defaultrdbms.driver=com.mysql.jdbc.Driver
progsets.spark.datasource.defaultrdbms.user=progsets
progsets.spark.datasource.defaultrdbms.password=progsetspwd

#
# Mongo - Spark
# 
# https://docs.mongodb.com/spark-connector/current/configuration/
#
progsets.spark.datasource.defaultmongodb.spark.read.format=com.mongodb.spark.sql
progsets.spark.datasource.defaultmongodb.spark.mongodb.input.uri=mongodb://localhost:27017
progsets.spark.datasource.defaultmongodb.spark.mongodb.input.database=facesix


#
# Solr
#
#
#
progsets.spark.datasource.defaultsolr.spark.read.format=solr
progsets.spark.datasource.defaultsolr.solr.zkhost=localhost:2181
progsets.spark.datasource.defaultsolr.solr.collection=erp
#progsets.spark.datasource.defaultsolr.solr.sort=u_f1
#progsets.spark.datasource.defaultsolr.solr.fields=f1,f2f3


#
# Cassandra
#
#https://github.com/datastax/spark-cassandra-connector/blob/master/doc/reference.md#cassandra-connection-parameters
#
progsets.spark.datasource.defaultcassandra.spark.read.format=org.apache.spark.sql.cassandra
progsets.spark.datasource.defaultcassandra.spark.cassandra.connection.host=localhost
#progsets.spark.datasource.defaultcassandra.spark.cassandra.connection.port=9042
